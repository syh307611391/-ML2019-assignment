{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Copy of A1_ReportDraft.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syh307611391/-ML2019-assignment/blob/master/Copy_of_A1_ReportDraft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX0vCMgQyZck",
        "colab_type": "text"
      },
      "source": [
        "# Draft and Experiment Area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1qTJit4yZcl",
        "colab_type": "text"
      },
      "source": [
        "1. First impression\n",
        "    * What is my chosen paper to read?\n",
        "    * What type of the main contribution the paper has made?\n",
        "        - A theory or proposition (revealing something, from unknown to known)\n",
        "        - A method or algorithm (inventing a technique, from undoable to doable)\n",
        "\n",
        "    * _Before_ reading the main body of the paper, write down your first impression  obtained from its abstract and short introduction.\n",
        "    * Why does the paper attract you, such as, How it surprised you? Why do you think it addresses an important topic that will be helpful in your future study of machine learning?\n",
        "    \n",
        "2. Read the paper abstract and introduction, list here all the notions that you don't know the precise meaning. If you think you have completed your list,  compare the list with people around you who have chosen the same or a similar paper.\n",
        "\n",
        "3. (During the next 7 days) Re-consider the central problem of the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vH2ob-6yZcm",
        "colab_type": "text"
      },
      "source": [
        "# Review Report on \"Gradient-Based Learning Applied to Document Recognition\"\n",
        "\n",
        "https://github.com/syh307611391/-ML2019-assignment/blob/master/Copy_of_A1_ReportDraft.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yXIwp8myZcn",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This report aims to evaluate the representative article, “Gradient-Based Learning Applied to Document Recognition”, by the authors Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. It was published in November 1998 by the IEEE. This literature review is organised as following different parts: Content will introduces the main parts of the literature; Innovation will evaluates the different points of some previous paper; Technical quality will talks about the quality of the experiments in this research; Application and X-factor will focuses on the application related to the introduced technology; and Presentation will evaluates the structure and the expression of this paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZENAKOjoyZcn",
        "colab_type": "text"
      },
      "source": [
        "## Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdHi06wTyZco",
        "colab_type": "text"
      },
      "source": [
        "The research is about .... A theorem has been proved stating ... / An algorithm of ... has been proposed.\n",
        "\n",
        "In this research article, those authors explored the concept of Gradient-Based Learning technique, one special method of Convolutional Neural Network used in this research called LeNet-5, and introduced a new paradigm called Graph Transformer Networks (GTN), which allows to apply to the task of handwritten character recognition. It also compares the performance of some different methods on handwritten digit recognition task. In order to build a system which can recognise the patterns like digits and characters with relying more on automatic learning instead of hand-designed heuristics[[LEC95]](http://yann.lecun.com/exdb/publis/pdf/lecun-95b.pdf), LeCun et al. described and evaluated two different systems for online handwriting recognition.\n",
        "###*2.1\tPattern recognition*\n",
        "In this paper, LeCun et al. estate the major purpose of this research is to build a better pattern recognition system by relying more on automatic learning instead of manual designed heuristics[[LEC95]](http://yann.lecun.com/exdb/publis/pdf/lecun-95b.pdf). In order to achieve this goal, the authors firstly evaluate the traditional pattern recognition, which consists two main modules, one is called feature extractor and the other is classifier, and they believe that the accuracy of this method is highly depend on the ability of designer and the set of features. In this research paper, LeCun et al. mainly focus on the system of handwriting recognition, and they illustrate that the challenges of the handwriting recognition are not only to recognise the characters themselves, but also to separate those recognised characters and interpret them into words and sentences.\n",
        "###*2.2\tLeNet-5*\n",
        "LeCun et al. introduce a Convolutional Neural Network called LeNet-5, which is used in the experiments of this research, and explain the architecture of LeNet-5. There are totally 7 layers in this module, and the input of LeNet-5 is a 32X32 pixel image. The first layer, which is known as Layer C1, has 6 feature maps and each one is connected to a 5x5 neighbourhood in the input. The next layer is Layer S2, which is a sub-sampling layer and has 4 14x14 feature maps, this layer is connected to a 2x2 neighbourhood in C1. Layer C3 is the third layer with 16 feature maps, and each unit is connected to S2 feature maps. The following layers are similar with the upper layers, they are connected to the next layers. Finally, the output layer is composed of Euclidean Radial Basis Function[[LEC95]](http://yann.lecun.com/exdb/publis/pdf/lecun-95b.pdf)[[LEC98]](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf).\n",
        "\n",
        "<img src=\"https://github.com/syh307611391/-ML2019-assignment/blob/master/F1.png?raw=true\" width=\"600\"/>\n",
        "\n",
        "Figure 1: the architecture of LeNet-5\n",
        "###*2.3\tComparative experiments*\n",
        "LeCun et al. decided to focus on the adaptive methods which operate on size-normalized images and compared such methods with other different methods of recognition[[LEC95]](http://yann.lecun.com/exdb/publis/pdf/lecun-95b.pdf). They compared various classification methods in different parameters, such as different version of database, the size of training set. Finally, they got the error rates of those method for test set, and they found that the method called Boosted LeNet-4, which the training set was augmented with artificially distorted examples, reach the lowest rate with only 0.7.\n",
        "\n",
        "<img src=\"https://github.com/syh307611391/-ML2019-assignment/blob/master/F2.png?raw=true\" width=\"600\"/>\n",
        "\n",
        "Figure 2: the results of error rate for different methods\n",
        "###*2.4\tGraph Transformer Network (GTN)*\n",
        "In order to build a better recognition system which mentioned in Pattern recognition, these authors found the systems called Graph Transformer Network makes the recognition process more easily and quickly. This system, GTN, uses graphs whose arcs carry information to represent the states and gradients[[LEC95]](http://yann.lecun.com/exdb/publis/pdf/lecun-95b.pdf). Also, the Gradient-Based Learning can be applied to GTN system.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAr1v-cMyZcp",
        "colab_type": "text"
      },
      "source": [
        "## Innovation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8rCipmMyZcp",
        "colab_type": "text"
      },
      "source": [
        "The background at the time of the work is that people understood the problem as .... The creative idea is ...\n",
        "\n",
        "###*3.1\tDataset*\n",
        "Before this research paper, the database the previous methods used was called NIST’s Special Database 3 and Special Database 1, which consists of binary images of handwritten digits[[LEC95]](http://yann.lecun.com/exdb/publis/pdf/lecun-95b.pdf). Usually, those previous methods used SD-3 as training set and SD-1 as test set. LeCun et al. discovered that, however, SD-3 was almost different from SD-1, because SD-3 was much cleaner, so they decided to generate a new database based on the SD-3 and SD-1. What they did was to mix the NIST’s datasets, and finally they named the resulting database as the Modified NIST dataset. Moreover, LeCun et al. used three different versions of MNIST database in order to improve the performance of those recognition methods. The first version is regular database, while the second is deslanted database, and the images in third version are 16x16 pixels(LeCun et al. 1998).\n",
        "\n",
        "<img src=\"https://github.com/syh307611391/-ML2019-assignment/blob/master/F3.png?raw=true\" width=\"400\"/>\n",
        "\n",
        "Figure 3: the examples from MNIST database\n",
        "###*3.2\tMulti-Layer Graph Transformer Networks*\n",
        "In this paper, LeCun et al. introduce a new conception of Graph Transformer Networks systems, which is quite different from the traditional multi-module systems. LeCun et al. insists that the multi-module systems are very flexible, but there are still some limitation and deficiency in the traditional neural networks, because the parameters in the traditional module are all fixed-size vectors, which will reduce the flexibility of communication of state information[[LEC95]](http://yann.lecun.com/exdb/publis/pdf/lecun-95b.pdf). The GTN systems they introduced can better solve such limitation and deficiency.\n",
        "\n",
        "<img src=\"https://github.com/syh307611391/-ML2019-assignment/blob/master/F4.png?raw=true\" width=\"400\"/>\n",
        "\n",
        "Figure 4: the traditional multi-module systems\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-vZOmv9yZcq",
        "colab_type": "text"
      },
      "source": [
        "## Technical quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLWRq88yyZcr",
        "colab_type": "text"
      },
      "source": [
        "The technical development if of high/low quality. The authors supported their theory using ...\n",
        "After reading this paper and some recent literatures related to LeNet-5 and GTN system, I think the technical quality of this paper is extremely high. It provides many detailed explanations about both LeNet-5 and GTN, and offers a plenty of comparison experiments, which include many related methods. For some explanations of the LeNet-5, it uses the introduction of Convolutional Neural Network as complement to help readers have a better understanding of LeNet-5. And in the experiment part, it not only just focuses on the results of the comparison, but also it introduces briefly about some methods in the experiments, for example, LeNet-1, LeNet-4 and Boosted LeNet-4, which are also performs well in character recognition. Moreover, it gives many examples of the characters in the database used, which can make the paper more convincing about why use MNIST as the dataset.\n",
        "\n",
        "<img src=\"https://github.com/syh307611391/-ML2019-assignment/blob/master/F5.png?raw=true\" width=\"700\"/>\n",
        "\n",
        "Figure 5: the examples from training and testing set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPz5aibOyZcs",
        "colab_type": "text"
      },
      "source": [
        "## Application and X-factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hql1DYUpyZcs",
        "colab_type": "text"
      },
      "source": [
        "I find the proposal in the paper promising. ...\n",
        "\n",
        "In this paper, the authors describe and explain two applications, one is on-line handwriting recognition and the other is GTN based check reading system. For the on-line handwriting recognition system, they built it based on four major modules: a pre-processor designed for determine a word or word group; a module used for capture the trajectory of the pen-based devices; a convolutional neural network for character recognition; a GTN system to interpret the output of the network. For the second application they describe, they evaluate the improvement of the check reading system based on GTN methodology: firstly, the data trained by the recognizer becomes bigger; secondly, due to the GTN, the new system take the grammar constraints into consideration, so that the accuracy perform better than previously; lastly, GTN methodology is more flexible in terms of testing heuristics, adjusting parameters and tuning the system[[KON19]](https://arxiv.org/pdf/1904.02342.pdf).\n",
        "\n",
        "For more application based one the technology that this research introduced, I think, it can be applied in the license plate number identification, which plays an important role in many real-life scenarios, for example, the car parking system, monitoring system[[WEI19]](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6339057/). For the car license plate number, the characters on it is simple and normalized, so the implementation can be quite easy, and the result can be very accurate, but the most challenge issue we need to solve is the time for recognition. And for the monitoring system, the image of the car plate number that the monitor captured can be not very clear and may cause some distortion because of the limitation of the camera pixel, so it will require much more distortion images of characters as training set to develop the recognizer. More than that, I think this method can be also used for the recognition of Chinese characters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwZhw_nAyZct",
        "colab_type": "text"
      },
      "source": [
        "## Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HRVKx0IyZcu",
        "colab_type": "text"
      },
      "source": [
        "The overall strucutre is clear. I found reading is easy / difficult. The paper could have been more attractive if the authors had organised ... / provided ... \n",
        "In terms of the presentation, the structure of this article is well-organized. In the Introduction part, the authors provide some background of the topic and detailed explain some concepts such as Gradient-Based Learning and Gradient Back-Propagation, which is beneficial for me who have never heard about such terms to understand. And in Introduction, they briefly introduce each flowing part of their study, which can help me to form a structure of this long research paper.\n",
        "\n",
        "For the depth of argument, they are well-explained in every mathematic formula, and in the experiments part, they are well-rounded to try to consider the factors as much as possible. And they also provide some understandable graphs with a clear explanation under the graphs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFsui6OkyZcu",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "[[LEC95]](http://yann.lecun.com/exdb/publis/pdf/lecun-95b.pdf): LeCun, Y., Jackel, L., Bottou, L., Brunot, A., Cortes, C., Denker, J., Drucker, H., Guyon, I., Muller, U. & Sackinger, E. 1995, 'Comparison of learning algorithms for handwritten digit recognition', vol. 60, Perth, Australia, pp. 53-60.\n",
        "\n",
        "[[LEC98]](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf): LeCun, Y., Bottou, L., Bengio, Y. & Haffner, P.J.P.o.t.I. 1998, 'Gradient-based learning applied to document recognition', vol. 86, no. 11, pp. 2278-324.\n",
        "\n",
        "[[EIS16]](https://link.springer.com/chapter/10.1007/978-3-319-48308-5_54): El-Sawy, A., Hazem, E.-B. & Loey, M. 2016, 'CNN for handwritten arabic digits recognition based on LeNet-5', Springer, pp. 566-75.\n",
        "\n",
        "[[WEI19]](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6339057/): Wei, G., Li, G., Zhao, J. & He, A.J.S. 2019, 'Development of a LeNet-5 Gas Identification CNN Structure for Electronic Noses', vol. 19, no. 1, p. 217.\n",
        "\n",
        "[[KON19]](https://arxiv.org/pdf/1904.02342.pdf): Koncel-Kedziorski, R., Bekal, D., Luan, Y., Lapata, M. & Hajishirzi, H.J.a.p.a. 2019, 'Text Generation from Knowledge Graphs with Graph Transformers'.\n",
        "\n"
      ]
    }
  ]
}